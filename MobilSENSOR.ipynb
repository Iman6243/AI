{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2Fjk6mtBCXvs",
        "ivTbmK_dgHex",
        "mToFGD-vgVrg",
        "folXaoXvX65p",
        "H-Hcs7rt2Ch7",
        "naU-6nXwXjER",
        "dgjv2wQIYJD4",
        "h5MEw7ZGZRTZ",
        "G0PkQMGleDuB",
        "XXE4FVv2fbia",
        "45VL-2d6iZlZ",
        "TRRO_7-ZkaPB",
        "BrjvdDUeQAXw",
        "msNE_RbDW5fT",
        "VMkereiD2LAU"
      ],
      "authorship_tag": "ABX9TyM7EUxqmai8Xp3tAT5ru77S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iman6243/AI/blob/main/MobilSENSOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clear All Variables"
      ],
      "metadata": {
        "id": "2Fjk6mtBCXvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f\n",
        "#del my_variable"
      ],
      "metadata": {
        "id": "wJ1ah4o-CS01"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PIP instaiitions"
      ],
      "metadata": {
        "id": "A_xmDApMqypN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  sktime-dl\n",
        "!pip install sktime[all_extras]\n",
        "!pip install dash\n",
        " # https://stumpy.readthedocs.io/en/latest/\n",
        "!pip install stumpy\n",
        "# https://towardsdatascience.com/a-brief-introduction-to-time-series-classification-algorithms-7b4284d31b97\n",
        "# https://github.com/sktime/sktime\n",
        "!pip install sktime"
      ],
      "metadata": {
        "id": "iCRY9hYfq52k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packges"
      ],
      "metadata": {
        "id": "ivTbmK_dgHex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dash\n",
        "import json\n",
        "import folium\n",
        "import socket\n",
        "import stumpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as pl\n",
        "from statistics import mean\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from dash import dcc, html, dcc\n",
        "from flask import Flask, request\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "import plotly.graph_objects as go\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from dash.dependencies import Output, Input\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage"
      ],
      "metadata": {
        "id": "Lbvo8quigEg4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Color and Style Plot"
      ],
      "metadata": {
        "id": "mToFGD-vgVrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the named colors\n",
        "named_colors = pl.colors.CSS4_COLORS\n",
        "# ایجاد آرایه برای ستون اول\n",
        "column1= list(named_colors.values())\n",
        "# ایجاد آرایه برای ستون دوم\n",
        "column2=list(named_colors.keys())\n",
        "# ایجاد آرایه برای ستون سوم\n",
        "column3 = pl.style.available\n",
        "# تنظیم طول لیست‌ها با اضافه کردن مقادیر NaN به لیست کوتاه‌تر\n",
        "max_len = max(len(column1), len(column2))\n",
        "column1.extend([np.nan] * (max_len - len(column1)))\n",
        "column2.extend([np.nan] * (max_len - len(column2)))\n",
        "column3.extend([np.nan] * (max_len - len(column3)))\n",
        "# ساخت دیتا فریم\n",
        "DF = pd.DataFrame({'ColorCod': column1,'ColorName': column2,'StylePlot':column3})"
      ],
      "metadata": {
        "id": "kxm6QbH_bFDP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "JtYmYb_hhEHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استخراج قله‌ها برای هر محور شتاب‌سنج\n",
        "def extract_peaks(axis_data):\n",
        "    peaks, _ = find_peaks(axis_data, height=0)\n",
        "    return peaks\n",
        "\n",
        "# ساخت داده‌های ویژگی براساس قله‌ها\n",
        "def create_feature_data(peaks, axis_data):\n",
        "    features = []\n",
        "    for peak in peaks:\n",
        "        feature = {'peak_value': axis_data[peak],'peak_distance': np.mean(np.diff(peaks))}\n",
        "        features.append(feature)\n",
        "    return features\n",
        "\n",
        "# تبدیل داده‌ها به توالی‌های سری زمانی\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        sequence = data[i:i+seq_length]\n",
        "        sequences.append(sequence)\n",
        "    return np.array(sequences)\n",
        "\n",
        "def is_prime(n):\n",
        "    if n <= 1:\n",
        "        return False\n",
        "    for i in range(2, int(n**0.5) + 1):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def print_primes(n, current=None):\n",
        "    if current is None:\n",
        "        current = n\n",
        "    if current < 0:\n",
        "        return\n",
        "    if is_prime(current):\n",
        "        print(current)\n",
        "    print_primes(n, current - 1)\n",
        "\n",
        "def count_sequences(lst, index=0, char=None, count=0):\n",
        "    if index == len(lst):  # Base case: end of the list\n",
        "        if char is not None:\n",
        "            print(f\"{char}: {count}\")\n",
        "        return\n",
        "\n",
        "    if lst[index] == char:\n",
        "        count_sequences(lst, index + 1, char, count + 1)\n",
        "    else:\n",
        "        if char is not None:\n",
        "            print(f\"{char}: {count}\")\n",
        "        count_sequences(lst, index + 1, lst[index], 1)\n",
        "\n",
        "def update_graph(_counter):\n",
        "\tdata = [\n",
        "\t\tgo.Scatter(x=list(time), y=list(d), name=name)\n",
        "\t\tfor d, name in zip([accel_x, accel_y, accel_z], [\"X\", \"Y\", \"Z\"])\n",
        "\t]\n",
        "\n",
        "\tgraph = {\n",
        "\t\t\"data\": data,\n",
        "\t\t\"layout\": go.Layout(\n",
        "\t\t\t{\n",
        "\t\t\t\t\"xaxis\": {\"type\": \"date\"},\n",
        "\t\t\t\t\"yaxis\": {\"title\": \"Acceleration ms<sup>-2</sup>\"},\n",
        "\t\t\t}\n",
        "\t\t),\n",
        "\t}\n",
        "\tif (\n",
        "\t\tlen(time) > 0\n",
        "\t):  #  cannot adjust plot ranges until there is at least one data point\n",
        "\t\tgraph[\"layout\"][\"xaxis\"][\"range\"] = [min(time), max(time)]\n",
        "\t\tgraph[\"layout\"][\"yaxis\"][\"range\"] = [\n",
        "\t\t\tmin(accel_x + accel_y + accel_z),\n",
        "\t\t\tmax(accel_x + accel_y + accel_z),\n",
        "\t\t]\n",
        "\n",
        "\treturn graph\n",
        "\n",
        "def data():  # listens to the data streamed from the sensor logger\n",
        "\tif str(request.method) == \"POST\":\n",
        "\t\tprint(f'received data: {request.data}')\n",
        "\t\tdata = json.loads(request.data)\n",
        "\t\tfor d in data['payload']:\n",
        "\t\t\tif (\n",
        "\t\t\t\td.get(\"name\", None) == \"accelerometer\"\n",
        "\t\t\t):  #  modify to access different sensors\n",
        "\t\t\t\tts = datetime.fromtimestamp(d[\"time\"] / 1000000000)\n",
        "\t\t\t\tif len(time) == 0 or ts > time[-1]:\n",
        "\t\t\t\t\ttime.append(ts)\n",
        "\t\t\t\t\t# modify the following based on which sensor is accessed, log the raw json for guidance\n",
        "\t\t\t\t\taccel_x.append(d[\"values\"][\"x\"])\n",
        "\t\t\t\t\taccel_y.append(d[\"values\"][\"y\"])\n",
        "\t\t\t\t\taccel_z.append(d[\"values\"][\"z\"])\n",
        "\treturn \"success\""
      ],
      "metadata": {
        "id": "Nn33Hb3ohIGm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReadData"
      ],
      "metadata": {
        "id": "4QxgtHEin2HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfAccel = pd.read_csv('Accelerometer.csv')\n",
        "dfGrav = pd.read_csv('Gravity.csv')\n",
        "dfLoc = pd.read_csv(\"Location.csv\")\n",
        "# فرض کنید که داده‌های شتاب‌سنج را در یک فایل CSV جمع‌آوری کرده‌اید\n",
        "signal=pd.read_csv(\"ACCL.csv\")"
      ],
      "metadata": {
        "id": "Uok969-Kn9ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulation-Sensors"
      ],
      "metadata": {
        "id": "msNE_RbDW5fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hostname = socket.gethostname()\n",
        "print(socket.gethostbyname(hostname))"
      ],
      "metadata": {
        "id": "MtDLfCCM5C7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfAccel.index = pd.to_datetime(dfAccel['time'], unit = 'ns')\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for axis in ['x', 'y', 'z']:\n",
        "    fig.add_trace(go.Scatter(x = dfAccel.index, y = dfAccel[axis], name = axis))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CZrAdPwu6cpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfGrav.index = pd.to_datetime(dfGrav['time'], unit='ns')\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for axis in ['x', 'y', 'z']:\n",
        "    fig.add_trace(go.Scatter(x = dfGrav.index, y = dfGrav[axis], name = axis))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "SkZyMx9X9RpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords = [(row.latitude, row.longitude) for _, row in dfLoc.iterrows()]\n",
        "\n",
        "my_map = folium.Map(location=[dfLoc.latitude.mean(), dfLoc.longitude.mean()], zoom_start=16)\n",
        "folium.PolyLine(coords, color=\"blue\", weight=5.0).add_to(my_map)"
      ],
      "metadata": {
        "id": "qOlGwiDBCs0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx2O8Ip2oL2x"
      },
      "outputs": [],
      "source": [
        "server = Flask(__name__)\n",
        "app = dash.Dash(__name__, server=server)\n",
        "\n",
        "MAX_DATA_POINTS = 1000\n",
        "UPDATE_FREQ_MS = 100\n",
        "\n",
        "time = deque(maxlen=MAX_DATA_POINTS)\n",
        "accel_x = deque(maxlen=MAX_DATA_POINTS)\n",
        "accel_y = deque(maxlen=MAX_DATA_POINTS)\n",
        "accel_z = deque(maxlen=MAX_DATA_POINTS)\n",
        "\n",
        "app.layout = html.Div(\n",
        "\t[\n",
        "\t\tdcc.Markdown(\n",
        "\t\t\tchildren=\"\"\"\n",
        "\t\t\t# Live Sensor Readings\n",
        "\t\t\tStreamed from Sensor Logger: tszheichoi.com/sensorlogger\n",
        "\t\t\"\"\"\n",
        "\t\t),\n",
        "\t\tdcc.Graph(id=\"live_graph\"),\n",
        "\t\tdcc.Interval(id=\"counter\", interval=UPDATE_FREQ_MS),\n",
        "\t]\n",
        ")\n",
        "\n",
        "\n",
        "@app.callback(Output(\"live_graph\", \"figure\"), Input(\"counter\", \"n_intervals\"))\n",
        "\n",
        "@server.route(\"/data\", methods=[\"POST\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tapp.run_server(port=8000, host=\"0.0.0.0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    your_time_series = np.random.rand(10000)\n",
        "    window_size = 50  # Approximately, how many data points might be found in a pattern\n",
        "\n",
        "    matrix_profile = stumpy.stump(your_time_series, m=window_size)\n",
        "\n",
        "subseq_len = 50\n",
        "correct_arc_curve, regime_locations = stumpy.fluss(matrix_profile[:, 1],L=subseq_len,n_regimes=2,excl_factor=1)"
      ],
      "metadata": {
        "id": "z_gtTvs2E7nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Signal Processing"
      ],
      "metadata": {
        "id": "sSAwCkGNrFY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# انتخاب ویژگی‌ها\n",
        "features = ['x', 'y', 'z']\n",
        "signal= signal[features]\n",
        "fig = plt.figure(figsize =(9, 7))\n",
        "#fig, ax = plt.subplots()\n",
        "#print(plt.style.available)\n",
        "plt.style.use('bmh')\n",
        "samples=int(len(signal)*10/1000)\n",
        "t = np.linspace(0, 1, samples)\n",
        "plt.figure(figsize=(7, 2))\n",
        "plt.boxplot(signal[:samples]['z'], vert=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RibWXmyJrkEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Filtering)"
      ],
      "metadata": {
        "id": "cuK9GYZ7XIJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Moving Average Filter)\n",
        "# مناسب برای هموار کردن سریع سیگنال‌ها با نویز کم"
      ],
      "metadata": {
        "id": "6CNKtNCiLymu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# فیلتر میانگین متحرک\n",
        "window_size = 10\n",
        "moving_average = pd.Series(signal[:samples]['z']).rolling(window=window_size).mean()\n",
        "\n",
        "# نمایش سیگنال اصلی و هموار شده\n",
        "plt.plot(t, signal[:samples]['z'], label='Original Signal')\n",
        "plt.plot(t, moving_average[:samples], label='Moving Average', color='red')\n",
        "plt.xlabel(\"Time Series\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GqN_tmGCL0I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Gaussian Filter)\n",
        "مناسب برای هموار کردن نرم‌تر و با قابلیت تنظیم سیگما"
      ],
      "metadata": {
        "id": "gbhXE0RmICE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استفاده از فیلتر گاوسی\n",
        "sigma = 2  # تنظیم مقدار سیگما\n",
        "gaussian_smoothed = gaussian_filter1d(signal, sigma=sigma)\n",
        "# نمایش سیگنال اصلی و هموار شده\n",
        "#plt.plot(t, signal, label='Original Signal')\n",
        "#plt.plot(t, gaussian_smoothed, label='Gaussian Smoothed', color='green')\n",
        "plt.plot(t,signal[:samples]['z'], label='Original Signal')\n",
        "plt.plot(t,gaussian_smoothed[:samples,2], label='Gaussian Smoothed', color='green')\n",
        "plt.xlabel(\"Time Series\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "1JvF6RCuEkPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Exponential Moving Average)\n",
        "وزن بیشتر به داده‌های جدیدتر برای تحلیل‌های سری‌های زمانی"
      ],
      "metadata": {
        "id": "EyOadiQ7T4pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# فیلتر میان‌گین متحرک نمایی\n",
        "alpha = 0.3\n",
        "ema = pd.Series(signal[:samples]['z']).ewm(alpha=alpha).mean()\n",
        "\n",
        "# نمایش سیگنال اصلی و هموار شده\n",
        "plt.plot(t, signal[:samples]['z'], label='Original Signal')\n",
        "plt.plot(t, ema[:samples], label='Exponential Moving Average', color='red')\n",
        "plt.xlabel(\"Time Series\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "TWM-fyPtT6qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Savitzky-Golay)\n",
        "مناسب برای هموار کردن و حفظ ویژگی‌های سیگنال"
      ],
      "metadata": {
        "id": "FrdT1SuQVf7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استفاده از فیلتر Savitzky-Golay\n",
        "window_length = 7  # باید فرد باشد\n",
        "polyorder = 2\n",
        "savgol_smoothed = savgol_filter(signal[:samples]['z'], window_length, polyorder)\n",
        "\n",
        "# نمایش سیگنال اصلی و هموار شده\n",
        "plt.plot(t, signal[:samples]['z'], label='Original Signal')\n",
        "plt.plot(t, savgol_smoothed[:samples], label='Savitzky-Golay', color='purple')\n",
        "plt.xlabel(\"Time Series\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "k3se5K_FVgj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feture Extraction"
      ],
      "metadata": {
        "id": "BrjvdDUeQAXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# نرمال‌سازی داده‌ها\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "peaks_x = extract_peaks(X_scaled[:, 0])\n",
        "peaks_y = extract_peaks(X_scaled[:, 1])\n",
        "peaks_z = extract_peaks(X_scaled[:, 2])\n",
        "\n",
        "features_x = create_feature_data(peaks_x, X_scaled[:, 0])\n",
        "features_y = create_feature_data(peaks_y, X_scaled[:, 1])\n",
        "features_z = create_feature_data(peaks_z, X_scaled[:, 2])\n",
        "\n",
        "# تبدیل داده‌های ویژگی به DataFrame\n",
        "df_features = pd.DataFrame(features_x + features_y + features_z)\n",
        "\n",
        "# آماده‌سازی داده‌ها برای مدلسازی\n",
        "X_features = df_features.values\n",
        "y_features = np.zeros(X_features.shape[0])  # فرض کنید برچسب‌های اولیه برای آموزش LSTM"
      ],
      "metadata": {
        "id": "mEvp53Vcrfi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##df_f = pd.DataFrame([{'peak_value': 1,'peak_distance': 2},{'peak_value': 3,'peak_distance': 4}]+[{'peak_value': -1,'peak_distance': -2},{'peak_value': -3,'peak_distance': -4}]+[{'peak_value': 5,'peak_distance': 6},{'peak_value': 7,'peak_distance': 8}])\n",
        "##X_f = df_f.values\n",
        "# آماده‌سازی داده‌ها برای مدلسازی\n",
        "##print(df_f)\n",
        "##print(df_f.values)\n",
        "##print(df_f.shape[1] )\n",
        "##X_f = X_f.reshape((X_f.shape[0], 1, X_f.shape[1]))\n",
        "##X_f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U48uUsQ6_9_r",
        "outputId": "4489df97-109a-4267-ac2b-cdb94ecbdb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ساخت و آموزش مدل LSTM\n",
        "# تغییر شکل داده‌ها برای LSTM\n",
        "X_features = X_features.reshape((X_features.shape[0], 1, X_features.shape[1]))\n",
        "\n",
        "# ایجاد مدل LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(1, X_features.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# کامپایل کردن مدل\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# آموزش مدل\n",
        "model.fit(X_features, y_features, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# ارزیابی مدل\n",
        "loss, mae = model.evaluate(X_features, y_features)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4n1fnoBSrDV1",
        "outputId": "d6de02f4-9743-4425-a2bb-01fdb2baf8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-585dd058201f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# پیش‌بینی با داده جدید\n",
        "peak_value=1.19969738746217\n",
        "peak_distance=6.666666666666667\n",
        "new_data = np.array([[peak_value, peak_distance]])\n",
        "new_data = new_data.reshape((new_data.shape[0], 1, new_data.shape[1]))\n",
        "\n",
        "prediction = model.predict(new_data)\n",
        "print(f'Prediction: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYLe1i_grYi1",
        "outputId": "ffade542-0777-4704-f10c-aef80a211589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
            "Prediction: [[4.138396e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# unsupervisor ML"
      ],
      "metadata": {
        "id": "folXaoXvX65p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## پیش‌پردازش و استخراج ویژگی‌ها:"
      ],
      "metadata": {
        "id": "H-Hcs7rt2Ch7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# فرض کنید که داده‌های سنسورها را در یک فایل CSV جمع‌آوری کرده‌اید\n",
        "data = dfAccel\n",
        "# انتخاب ویژگی‌ها\n",
        "features= ['x', 'y', 'z']\n",
        "x=data[features]\n",
        "# نرمال‌سازی داده‌ها\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# استخراج ویژگی‌های آماری\n",
        "def extract_features(row):\n",
        "  features = []\n",
        "  for i in range(row.shape[0]):\n",
        "    mean = np.mean(row[i])\n",
        "    std = np.std(row[i])\n",
        "    max_val = np.max(row[i])\n",
        "    min_val = np.min(row[i])\n",
        "    features.extend([mean, std, max_val, min_val])\n",
        "  return np.array(features)\n",
        "# اعمال تابع extract_features به هر ستون\n",
        "#X_features = np.apply_along_axis(extract_features, 1, X_scaled)\n",
        "X_features = np.apply_along_axis(lambda row: extract_features(row.reshape(1, -1)), 1, X_scaled)\n",
        " # اطمینان از مطابقت طول‌ها\n",
        "print(X_features.shape)\n",
        "print(x.shape)\n",
        "#print(len(X_features))\n",
        "#print(len(data))"
      ],
      "metadata": {
        "id": "kH9aoHDmygyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## اجرای مدل K-Means:"
      ],
      "metadata": {
        "id": "naU-6nXwXjER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استفاده از الگوریتم K-Means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)  # تعداد کلاسترها را مشخص کنید\n",
        "kmeans.fit(X_features)\n",
        "\n",
        "# افزودن نتایج کلاسترینگ به داده‌ها\n",
        "data['cluster'] = kmeans.labels_\n",
        "\n",
        "# نمایش نتایج\n",
        "plt.scatter(data['x'], data['y'], c=data['cluster'])\n",
        "plt.xlabel('Accelerometer X')\n",
        "plt.ylabel('Accelerometer Y')\n",
        "plt.title('K-Means Clustering')\n",
        "plt.show()\n",
        "\n",
        "# بررسی ویژگی‌های هر کلاستر\n",
        "print(data.groupby('cluster').mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "KODKbnJo2ffS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## اجرای مدل DBSCAN:"
      ],
      "metadata": {
        "id": "dgjv2wQIYJD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# استفاده از الگوریتم DBSCAN\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "clusters = dbscan.fit_predict(X_features)\n",
        "\n",
        "# افزودن نتایج کلاسترینگ به داده‌ها\n",
        "data['cluster'] = clusters\n",
        "\n",
        "# نمایش نتایج\n",
        "plt.scatter(data['x'], data['y'], c=data['cluster'])\n",
        "plt.xlabel('Accelerometer X')\n",
        "plt.ylabel('Accelerometer Y')\n",
        "plt.title('K-Means Clustering')\n",
        "plt.show()\n",
        "\n",
        "# بررسی ویژگی‌های هر کلاستر\n",
        "print(data.groupby('cluster').mean())\n"
      ],
      "metadata": {
        "id": "2id3Ge0KYOiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## اجرای مدل Hierarchical Clustering:"
      ],
      "metadata": {
        "id": "h5MEw7ZGZRTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استفاده از الگوریتم Hierarchical Clustering\n",
        "linked = linkage(X_features, method='ward')\n",
        "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
        "plt.show()\n",
        "\n",
        "# اجرای مدل Agglomerative Clustering\n",
        "hc = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='ward')\n",
        "clusters = hc.fit_predict(X_features)\n",
        "\n",
        "# افزودن نتایج کلاسترینگ به داده‌ها\n",
        "data['cluster'] = clusters\n",
        "\n",
        "# نمایش نتایج\n",
        "plt.scatter(data['x'], data['y'], c=data['cluster'])\n",
        "plt.xlabel('Accelerometer X')\n",
        "plt.ylabel('Accelerometer Y')\n",
        "plt.title('K-Means Clustering')\n",
        "plt.show()\n",
        "\n",
        "# بررسی ویژگی‌های هر کلاستر\n",
        "print(data.groupby('cluster').mean())\n"
      ],
      "metadata": {
        "id": "Y-e9rwQwZTXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## کد تحلیل الگوها"
      ],
      "metadata": {
        "id": "G0PkQMGleDuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# تحلیل الگوهای هر کلاستر\n",
        "clusters = data['cluster'].unique()\n",
        "\n",
        "for cluster in clusters:\n",
        "    cluster_data = data[data['cluster'] == cluster]\n",
        "    print(f\"Cluster {cluster}:\")\n",
        "    print(cluster_data.describe())\n"
      ],
      "metadata": {
        "id": "oJQJCzlqeF0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## کد برای کلاسترینگ و ایجاد برچسب‌های اولیه"
      ],
      "metadata": {
        "id": "XXE4FVv2fbia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استفاده از الگوریتم K-Means برای کلاسترینگ\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(X_scaled)\n",
        "data['pseudo_labels'] = kmeans.labels_\n",
        "\n",
        "# استفاده از برچسب‌های اولیه برای آموزش مدل نظارتی\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, data['pseudo_labels'], test_size=0.2, random_state=42)\n",
        "\n",
        "# آموزش مدل Random Forest\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ارزیابی مدل\n",
        "predictions = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBthaIw-fgZx",
        "outputId": "1a5dff7e-03da-439c-db6f-db2ce8bf1a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.07189479768786126\n",
            "سه مقدار شتاب  بترتیب در راستای محورهای طول و عرض و ارتفاع وارد کنید: 55,26,87\n",
            "Prediction: [1.68]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "45VL-2d6iZlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# پیش‌بینی با داده جدید\n",
        "#new_data = np.array([[accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z, magnet_x, magnet_y, magnet_z]])\n",
        "accel_x, accel_y, accel_z = eval(input(\"سه مقدار شتاب بترتیب در راستای محورهای طول و عرض و ارتفاع وارد کنید: \"))\n",
        "new_data = np.array([[accel_x, accel_y, accel_z]])\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "new_prediction = model.predict(new_data_scaled)\n",
        "print(f\"Prediction: {new_prediction}\")"
      ],
      "metadata": {
        "id": "pI8VpGuJiXDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM برای تحلیل داده‌های سری زمانی"
      ],
      "metadata": {
        "id": "TRRO_7-ZkaPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 10  # طول توالی‌ها\n",
        "X_sequences = create_sequences(X_scaled, seq_length)\n",
        "\n",
        "# استفاده از الگوریتم K-Means برای کلاسترینگ و ایجاد برچسب‌های اولیه\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "pseudo_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# همگام‌سازی برچسب‌ها با توالی‌ها\n",
        "y_sequences = pseudo_labels[seq_length:]\n",
        "\n",
        "# ایجاد مدل LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(seq_length, X_sequences.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))  # خروجی مدل براساس تعداد کلاسترها یا برچسب‌های اولیه\n",
        "\n",
        "# کامپایل کردن مدل\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# آموزش مدل\n",
        "model.fit(X_sequences, y_sequences, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# ارزیابی مدل\n",
        "loss, mae = model.evaluate(X_sequences, y_sequences)\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "\n",
        "# پیش‌بینی با داده جدید\n",
        "new_data = np.array([X_scaled[-seq_length:]])\n",
        "prediction = model.predict(new_data)\n",
        "print(f'Prediction: {prediction}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU4A8svCkmep",
        "outputId": "d8ea5d15-a2db-4c99-a5f1-9793f6944dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-10"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Prime"
      ],
      "metadata": {
        "id": "VMkereiD2LAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ورودی عدد صحیح\n",
        "number = int(input(\"یک عدد صحیح وارد کنید: \"))\n",
        "print_primes(number)"
      ],
      "metadata": {
        "id": "SplwIk40oLDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "characters = ['a', 'a', 'b', 'b', 'b', 'c', 'a', 'a', 'd', 'd', 'd', 'd']\n",
        "count_sequences(characters)"
      ],
      "metadata": {
        "id": "unFjLTtpZK6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مقادیر واقعی و پیش‌بینی\n",
        "y_true = [0, 0, 1, 1]\n",
        "y_scores = [0.2, 0.5, 0.35, 0.8]\n",
        "\n",
        "# محاسبه حساسیت و 1-اختصاصی‌بودن\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "# محاسبه AUC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# رسم نمودار ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
        "plt.xlabel('1 - Specificity (FPR)')\n",
        "plt.ylabel('Sensitivity (TPR)')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b8nJWX444kPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}